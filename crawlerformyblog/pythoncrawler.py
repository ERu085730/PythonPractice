# -*- coding: utf-8 -*-
"""PythonCrawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pfN1uEeFKxYo8LY0d6v3JTjRPCuMDl20
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

# target page
url = "https://eru085730.github.io/"

# crawler page
craw = requests.get(url)

#set the val save the data
w_content = craw.text

#decode  html data
soup = BeautifulSoup(w_content, 'lxml')

#find target element
t_element = soup.find_all('h1', class_="post-title")
t_element

#data
da = [e.text for e in t_element ]
da

an = []
for bn in zip(da):
        bn = str(bn)
        bn= bn[4:len(bn)-5]
        an.append(bn)
        
sh = pd.DataFrame({
    "Title" : an
})

sh.head()